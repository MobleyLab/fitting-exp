#!/usr/bin/env bash
#SBATCH -J benchmark_parallel
#SBATCH -p free
#SBATCH -t 1-00:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=8
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=8gb
#SBATCH --array=1-250
#SBATCH --account dmobley_lab
#SBATCH --export ALL
#SBATCH --requeue

# Set the output and error output paths.
#SBATCH -o  ./slurm_output/slurm-%J.out
#SBATCH -e  ./slurm_output/slurm-%J.err
#


. ~/.bashrc
# Use the right conda environment
conda activate /dfs6/pub/pbehara/bin/conda/openff-force-fields
#conda env export > conda_env.yaml
python 02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -ff openff_unconstrained-1.2.0.offxml -o 02-outputs/openff-1-2-0-"$SLURM_ARRAY_TASK_ID".sdf
python 02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -ff openff_unconstrained-1.3.0.offxml -o 02-outputs/openff-1-3-0-"$SLURM_ARRAY_TASK_ID".sdf
python 02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -ff openff_unconstrained-2.0.0-rc.1.offxml -o 02-outputs/openff-2-0-0-"$SLURM_ARRAY_TASK_ID".sdf
#python 02-b-minimize.py -i 02-chunks/chunk-"$SLURM_ARRAY_TASK_ID".sdf -ff sage_rc1_refit_with_dih_denom.offxml -o 02-outputs/openff-2-dd-"$SLURM_ARRAY_TASK_ID".sdf

